{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edcb4108-df0b-49f6-a56d-64f672c83df3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3604359517.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [1]\u001b[1;36m\u001b[0m\n\u001b[1;33m    Vincent Cavanna - Comp Phys Exam 1\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Vincent Cavanna - Comp Phys Exam 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7642de7-fa0f-4710-ad35-91da04d63371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1a What is the difference between using  np.arange(1,10) and np.linspace(1,10,100)?\n",
    "\"\"\"\n",
    "np.arange(1,10) outputs a numpy array including the elements that start at 1 and ending when the increment (\"step\") reaches the\n",
    "second number (10). Default step is 1.\n",
    "Output: array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "np.linspace(1,10,100) outputs a numpy array with 100 elements equally spaced apart, starting at 1 and ending at 10.\n",
    "Output: array([ 1.        ,  1.09090909,  1.18181818,  1.27272727,\n",
    "        ...\n",
    "        9.72727273,  9.81818182,  9.90909091, 10.        ])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef47fef2-1327-429b-83dd-3b0c8c90f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1b What is the difference between NumPy loadtxt() and NumPy genfromtxt()?\n",
    "\"\"\"\n",
    "numpy loadtxt() will load data from text.\n",
    "genfromtxt() does the same thing, but also has a way to handle null or empty values.\n",
    "\n",
    "For this reason, genfromtxt() is preferrred over loadtxt(), since a csv will sometimes have empty values.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733045e2-c281-4f28-8a0f-fad5d191d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1c What does vectorization of math refer to in Python?  Give an example.\n",
    "\"\"\"\n",
    "Vectorization refers to the use of standard, time-optimized functions over a preference for loops and other more time-intensive\n",
    "operations.\n",
    "One example of this is the vectorization of the numpy.dot() function over a loop. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f234e129-2cd7-4c22-b264-af68ad54d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1d  What command lines are needed to plot four graphs in separates panels with two graphs next to each other as inside one figure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3793697-6fe0-4be5-9121-322c9fcaa762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Sep 25 00:24:47 2022\n",
    "\n",
    "@author: Vincent\n",
    "exam 1 problem 2\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.loadtxt(\"WASP24TESSexcerpt.csv\",dtype=float,delimiter =\",\")\n",
    "\n",
    "x, y = data[:,0],data[:,1]\n",
    "\n",
    "plt.plot(x,y,'b.')\n",
    "\n",
    "sortedData = np.sort(data,1)\n",
    "\n",
    "np.savetxt(\"sorted_WASP24TESSexcerpt.csv\",sortedData,delimiter=\",\",fmt=\"%s\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "12.163825\n",
    "2692.958861\n",
    "6511.8687  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd9d25d-5d1e-4761-9cae-31cab31a5019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Sep 25 00:41:02 2022\n",
    "\n",
    "@author: Vincent\n",
    "Exam1_3\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def madelung(x):\n",
    "    # It seems that i, j, k, are always equal. Therefore, I simply use x for all three.\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    val = 1 / math.sqrt((x**2) * 3)\n",
    "    if x % 2 == 1:\n",
    "        val = val * -1\n",
    "    return val\n",
    "\n",
    "L = 100\n",
    "\n",
    "iteration = range(L*-1, L+1)\n",
    "\n",
    "madelung_sum = np.sum([madelung(i) for i in iteration])\n",
    "\n",
    "print(\"The Madelung constant is {0:10f} for when L = {1}\".format(madelung_sum,L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f7a52-4637-4aff-96ad-f6ed4baaa37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Sep 25 00:59:08 2022\n",
    "\n",
    "@author: Vincent\\\n",
    "exam1_4\n",
    "\n",
    "================\n",
    "What is amazing about this method of calculating π?\n",
    "It's extreme accuracy after just a few iterations (i.e. the drastic improvement from n=1 to n=2.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def sumFunction(n):\n",
    "    val = np.float64(math.factorial(4*n) * (1103 + 26390*n) /((math.factorial(n) ** 4) * 396**(4*n)))\n",
    "    return val\n",
    "\n",
    "def convergeToPi(n):\n",
    "    sum = 0\n",
    "    sum = 1 / (np.float64(np.sum([sumFunction(i) for i in range(n)]) * 2 * math.sqrt(2) / 9801))\n",
    "    return sum\n",
    "\n",
    "print(convergeToPi(1))\n",
    "print(convergeToPi(2))\n",
    "print(np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d20212-2024-4d96-8381-451cd5a1d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Sep 25 14:46:16 2022\n",
    "\n",
    "@author: Vincent\n",
    "exam1_5.py\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.loadtxt('antarctica_mass_200204_202006.txt',float, skiprows=31)\n",
    "\n",
    "x = np.array(data[:,0]) # independent variable - (year.decimal)\n",
    "y = np.array(data[:,1]) # dependent variable - Antarctic mass (Gigatonnes)\n",
    "sig_y = np.array(data[:,2]) # standard deviation - Antarctic mass uncertainty (Gigatonnes)\n",
    "N = len(x)              #number of data points\n",
    "\n",
    "#define least squares fit\n",
    "def leastsqrs(x,y):\n",
    "    #initialize our variables\n",
    "    sum_x = 0\n",
    "    sum_y = 0\n",
    "    sum_xy = 0\n",
    "    sum_xx = 0\n",
    "    A = 0\n",
    "    B = 0\n",
    "    \n",
    "    #perform sums\n",
    "    sum_x = np.sum(x)\n",
    "    sum_y = np.sum(y)\n",
    "    sum_xx = np.inner(x, x)\n",
    "    sum_xy = np.inner(x, y)\n",
    "    \n",
    "    # determine the coefficients A and B\n",
    "    Delta = N*sum_xx  - sum_x*sum_x\n",
    "    A = (sum_xx*sum_y - sum_x*sum_xy) / Delta\n",
    "    B = (N*sum_xy - sum_x*sum_y) / Delta\n",
    "    sig_A = np.mean(sig_y)*np.sqrt(np.sum(x**2 / Delta))\n",
    "    sig_B = np.mean(sig_y)*np.sqrt(N / Delta)\n",
    "    \n",
    "    return [A,B,sig_A, sig_B]\n",
    "\n",
    "# Calculate chi square\n",
    "def chi_calc(x,y,sig_y,A,B):\n",
    "    chi_square = 0\n",
    "    chi_square = np.sum(((y - (A + B * x)) ** 2) / (2 * sig_y ** 2))\n",
    "    return chi_square\n",
    "\n",
    "#Define the correlation coefficient\n",
    "def r(x,y):\n",
    "    r = 0\n",
    "    sum_diff_xy = 0\n",
    "    sum_xdiff_squared = 0\n",
    "    sum_ydiff_squared = 0\n",
    "    x_bar = np.mean(x)\n",
    "    y_bar = np.mean(y)\n",
    "    sum_xdiff_squared = np.sum((x - x_bar)**2)\n",
    "    sum_ydiff_squared = np.sum((y - y_bar)**2)\n",
    "    sum_diff_xy = np.sum((x - x_bar)*(y - y_bar))\n",
    "    r = sum_diff_xy/np.sqrt(sum_xdiff_squared*sum_ydiff_squared)\n",
    "    return r\n",
    "\n",
    "#Find the Pearson correlation coefficient for the data.\n",
    "print('a) the correlation coefficient r = {0:5.2f}'.format(r(x,y)))\n",
    "\n",
    "#Determine the linear regression for the data.\n",
    "A, B, sig_A, sig_B = leastsqrs(x, y)\n",
    "print('b) The linear regression is Y = AX + B')\n",
    "print('   where A = {0:5.2f}, B = {1:5.2f} '.format(A,B))\n",
    "\n",
    "\n",
    "print(\"c) starting now\")\n",
    "#Plot the data and the model curve (linear regression).\n",
    "plt.plot(x,y,'bo')\n",
    "xc = np.linspace(min(x), max(x),50)\n",
    "yc = A + B*xc\n",
    "plt.plot(xc,yc,'r-')\n",
    "plt.legend(('Least Squares Fit', 'Data', 'Residuals'),loc = 0)\n",
    "plt.title('Antarctic mass measurements, GRACE, 04/2002 - 06/2020')\n",
    "plt.xlabel('TIME (year)')\n",
    "plt.ylabel('Antarctic mass (gigatonnes)')\n",
    "plt.show()\n",
    "print(\"   ...finished.\")\n",
    "\n",
    "#Evaluate the goodness of the fit.\n",
    "print(\"d) The fit of the linear regression closely matches the data. It's good.\")\n",
    "\n",
    "#What do you note about yearly and decadal changes in mass?\n",
    "print(\"e) It has a downward slope of about 143 gigatonnes per year.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fad2ce-1c11-4b53-9912-48f468a0befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Sep 25 15:39:09 2022\n",
    "\n",
    "@author: Vincent\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze(file):\n",
    "    data = np.loadtxt(file,float, skiprows=1)\n",
    "    \n",
    "    x = np.array(data[:,0]) # independent variable\n",
    "    y = np.array(data[:,1]) # dependent variable\n",
    "    sig_y = np.array(data[:,2]) # standard deviation\n",
    "    N = len(x)              #number of data points\n",
    "    \n",
    "    #define least squares fit\n",
    "    def leastsqrs(x,y):\n",
    "        #initialize our variables\n",
    "        sum_x = 0\n",
    "        sum_y = 0\n",
    "        sum_xy = 0\n",
    "        sum_xx = 0\n",
    "        A = 0\n",
    "        B = 0\n",
    "        \n",
    "        #perform sums\n",
    "        sum_x = np.sum(x)\n",
    "        sum_y = np.sum(y)\n",
    "        sum_xx = np.inner(x, x)\n",
    "        sum_xy = np.inner(x, y)\n",
    "        \n",
    "        # determine the coefficients A and B\n",
    "        Delta = N*sum_xx  - sum_x*sum_x\n",
    "        A = (sum_xx*sum_y - sum_x*sum_xy) / Delta\n",
    "        B = (N*sum_xy - sum_x*sum_y) / Delta\n",
    "        sig_A = np.mean(sig_y)*np.sqrt(np.sum(x**2 / Delta))\n",
    "        sig_B = np.mean(sig_y)*np.sqrt(N / Delta)\n",
    "        \n",
    "        return [A,B,sig_A, sig_B]\n",
    "    \n",
    "    # Calculate chi square\n",
    "    def chi_calc(x,y,sig_y,A,B):\n",
    "        chi_square = 0\n",
    "        chi_square = np.sum(((y - (A + B * x)) ** 2) / (2 * sig_y ** 2))\n",
    "        return chi_square\n",
    "    \n",
    "    #Define the correlation coefficient\n",
    "    def r(x,y):\n",
    "        r = 0\n",
    "        sum_diff_xy = 0\n",
    "        sum_xdiff_squared = 0\n",
    "        sum_ydiff_squared = 0\n",
    "        x_bar = np.mean(x)\n",
    "        y_bar = np.mean(y)\n",
    "        sum_xdiff_squared = np.sum((x - x_bar)**2)\n",
    "        sum_ydiff_squared = np.sum((y - y_bar)**2)\n",
    "        sum_diff_xy = np.sum((x - x_bar)*(y - y_bar))\n",
    "        r = sum_diff_xy/np.sqrt(sum_xdiff_squared*sum_ydiff_squared)\n",
    "        return r\n",
    "    \n",
    "    A, B, sig_A, sig_B = leastsqrs(x, y)\n",
    "    \n",
    "    print(\"For {0}\".format(file))\n",
    "    print('  Number of data points = ', N)\n",
    "    print('  A = {0:5.2f}, +/- {1:5.2f} (Mpc), B = {2:5.2f} +/- {3:5.2f} (km/s)'.format(A,sig_A,B,sig_B))\n",
    "    print('  The slope of the straight line, {0:5.2f} (km/s), is the Hubble- Lemaître constant.'.format(B))\n",
    "    \n",
    "    \n",
    "    chi_square = chi_calc(x,y,sig_y,A,B)\n",
    "    print('  chi_square = {0:5.2f}'.format(chi_square))\n",
    "    print('  chi_square/dof = {0:6.2f}'.format(chi_square/(N-2)))\n",
    "    print('  the correlation coefficient r = {0:5.2f}'.format(r(x,y)))\n",
    "    print(\"  I don't think we need the uncertainty of r\")\n",
    "    print(\"\\n====================================================\\n\")\n",
    "\n",
    "def analyzeModd(file):\n",
    "    data = np.loadtxt(file,float, skiprows=1)\n",
    "    \n",
    "    x = np.array(data[:,0]) # independent variable\n",
    "    y = np.array(data[:,1]) # dependent variable\n",
    "    sig_y = np.array(data[:,2]) # standard deviation\n",
    "    N = len(x)              #number of data points\n",
    "    \n",
    "    #define least squares fit\n",
    "    def leastsqrs(x,y):\n",
    "        #initialize our variables\n",
    "        sum_x = 0\n",
    "        sum_y = 0\n",
    "        sum_xy = 0\n",
    "        sum_xx = 0\n",
    "        A = 0\n",
    "        B = 0\n",
    "        \n",
    "        #perform sums\n",
    "        sum_x = np.sum(x)\n",
    "        sum_y = np.sum(y)\n",
    "        sum_xx = np.inner(x, x)\n",
    "        sum_xy = np.inner(x, y)\n",
    "        \n",
    "        # determine the coefficients A and B\n",
    "        Delta = N*sum_xx  - sum_x*sum_x\n",
    "        A = (sum_xx*sum_y - sum_x*sum_xy) / Delta\n",
    "        B = (N*sum_xy - sum_x*sum_y) / Delta\n",
    "        sig_A = np.mean(sig_y)*np.sqrt(np.sum(x**2 / Delta))\n",
    "        sig_B = np.mean(sig_y)*np.sqrt(N / Delta)\n",
    "        \n",
    "        return [A,B,sig_A, sig_B]\n",
    "    \n",
    "    # Calculate chi square\n",
    "    def chi_calc(x,y,sig_y,A,B):\n",
    "        chi_square = 0\n",
    "        chi_square = np.sum(((y - (A + B * x)) ** 2) / (2 * sig_y ** 2))\n",
    "        return chi_square\n",
    "    \n",
    "    #Define the correlation coefficient\n",
    "    def r(x,y):\n",
    "        r = 0\n",
    "        sum_diff_xy = 0\n",
    "        sum_xdiff_squared = 0\n",
    "        sum_ydiff_squared = 0\n",
    "        x_bar = np.mean(x)\n",
    "        y_bar = np.mean(y)\n",
    "        sum_xdiff_squared = np.sum((x - x_bar)**2)\n",
    "        sum_ydiff_squared = np.sum((y - y_bar)**2)\n",
    "        sum_diff_xy = np.sum((x - x_bar)*(y - y_bar))\n",
    "        r = sum_diff_xy/np.sqrt(sum_xdiff_squared*sum_ydiff_squared)\n",
    "        return r\n",
    "    \n",
    "    A, B, sig_A, sig_B = leastsqrs(x, y)\n",
    "    \n",
    "    B = np.sum(x*y) / np.sum(x*x)\n",
    "    \n",
    "    print(\"MODDED: For {0}\".format(file))\n",
    "    print('  Number of data points = ', N)\n",
    "    print('  A = {0:5.2f}, +/- {1:5.2f} (Mpc), B = {2:5.2f} +/- {3:5.2f} (km/s)'.format(A,sig_A,B,sig_B))\n",
    "    print('  The slope of the straight line, {0:5.2f} (km/s), is the Hubble- Lemaître constant.'.format(B))\n",
    "    \n",
    "    \n",
    "    chi_square = chi_calc(x,y,sig_y,A,B)\n",
    "    print('  chi_square = {0:5.2f}'.format(chi_square))\n",
    "    print('  chi_square/dof = {0:6.2f}'.format(chi_square/(N-2)))\n",
    "    print('  the correlation coefficient r = {0:5.2f}'.format(r(x,y)))\n",
    "    print(\"  I don't think we need the uncertainty of r\")\n",
    "    print(\"\\n====================================================\\n\")\n",
    "\n",
    "analyze(\"Lemaitre.txt\")\n",
    "analyze(\"Hubble.txt\")\n",
    "analyzeModd(\"Lemaitre.txt\")\n",
    "analyzeModd(\"Hubble.txt\")\n",
    "\n",
    "print(\"From your analysis, which data set has the stronger correlation?\")\n",
    "print(\"   The Hubble data has a better correlation,since B = 439.51 in Hubble's and that changes\\n only slightly to 412.91 with a better estimate.\\n\")\n",
    "print(\"Which data set has the better chi-squared per degrees of freedom?\")\n",
    "print(\"   The better chi-squared would be the smaller chi-squared, which is B at 22.24.\\n\")\n",
    "print(\"For which data set does the value of the Hubble-Lemaître constant remain nearly the same for non-zero and zero intercept?\")\n",
    "print(\"   The value remains the same for Hubble's the most, from 439.51 to 412.91.\")\n",
    "print(\"Whose data would you say was better?  Why?\")\n",
    "print(\"   Hubble's data was better. It minimized the coefficients for Hubble, and its constant remained more constant :)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
